{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +\n",
    "import warnings\n",
    "\n",
    "# Essentials\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Stain normalization\n",
    "import stain_norm.stain_utils as utils\n",
    "import stain_norm.vahadane as vahadane\n",
    "\n",
    "# Image functions\n",
    "from PIL import Image\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import canny\n",
    "from skimage.morphology import binary_closing, binary_dilation, disk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "IMPATH = '/home/as3ek/data/lizard/images/all_images/'\n",
    "LBLPATH = '/home/as3ek/data/lizard/labels/Labels/'\n",
    "patch_size = 128\n",
    "resize_to = 128\n",
    "target_images_path = '/home/as3ek/data/lizard_split_norm_bright3/images/' # for unnormalized patches\n",
    "target_classes_path = '/home/as3ek/data/lizard_split_norm_bright3/classes/' # for unnormalized patches\n",
    "target_instances_path = '/home/as3ek/data/lizard_split_norm_bright3/instances/' # for unnormalized patches\n",
    "save_WSI = False\n",
    "overlap = 0.5 # %-age area\n",
    "random.seed(42)\n",
    "\n",
    "# Create splits\n",
    "test_percent = 7.5\n",
    "splits = [\"train\", \"test\"]\n",
    "for splt in splits:\n",
    "    os.makedirs(os.path.join(target_images_path, splt), exist_ok=True)\n",
    "    os.makedirs(os.path.join(target_classes_path, splt), exist_ok=True)\n",
    "    os.makedirs(os.path.join(target_instances_path, splt), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maps(label_pth):\n",
    "    # Load label\n",
    "    label = sio.loadmat(label_pth) #! This filename is a placeholder!\n",
    "    # Load the instance segmentation map.\n",
    "    # This map is of type int32 and contains values from 0 to N, where 0 is background\n",
    "    # and N is the number of nuclei. \n",
    "    # Shape: (H, W) where H and W is the height and width of the image.\n",
    "    inst_map = label['inst_map'] \n",
    "\n",
    "    # Load the index array. This determines the mapping between the nuclei in the instance map and the\n",
    "    # corresponing provided categories, bounding boxes and centroids.\n",
    "    nuclei_id = label['id'] # shape (N, 1), where N is the number of nuclei.\n",
    "\n",
    "    # Load the nuclear categories / classes. \n",
    "    # Shape: (N, 1), where N is the number of nuclei.\n",
    "    classes = label['class']\n",
    "    \n",
    "    # Map neucli to classes by id\n",
    "    id_class_map = {nuclei_id[i][0]: classes[i][0] for i in range(len(nuclei_id))}\n",
    "    \n",
    "    # Replace id in instance map by class id\n",
    "    class_map = np.copy(inst_map)\n",
    "    for k, v in id_class_map.items():\n",
    "        class_map[inst_map==k] = v\n",
    "        \n",
    "    # Convert to PIL images\n",
    "    inst_pil = Image.fromarray(inst_map)\n",
    "    class_pil = Image.fromarray(class_map)\n",
    "    \n",
    "    return inst_pil, class_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize normalizer\n",
    "target = utils.read_image('/scratch/as3ek/datasets/lizard/images/all_images/dpath_11.png')\n",
    "normalizer = vahadane.Normalizer()\n",
    "normalizer.fit(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "238it [35:57, 13.52s/it]\n"
     ]
    }
   ],
   "source": [
    "num_files = len(os.listdir(IMPATH))\n",
    "\n",
    "for i, file in tqdm(enumerate(list(reversed(os.listdir(IMPATH))))):\n",
    "    img_path = os.path.join(IMPATH, file)\n",
    "    filename = file.split('.')[0]\n",
    "    label_path = os.path.join(LBLPATH, filename)\n",
    "    \n",
    "    # image = Image.open(img_path).convert(\"RGB\")\n",
    "    image = utils.read_image(img_path)\n",
    "    inst, clz = get_maps(label_path)\n",
    "    \n",
    "    # Stain normalize image\n",
    "    image = normalizer.transform(image)\n",
    "    # Normalize brightness\n",
    "    image = utils.standardize_brightness(image)\n",
    "    image = Image.fromarray(image)\n",
    "    \n",
    "    # Initialize x and y coord\n",
    "    x_cord = 0\n",
    "    y_cord = 0\n",
    "    \n",
    "    # For last row and column\n",
    "    last_x = False\n",
    "    last_y = False\n",
    "    \n",
    "    # Decide split for this image\n",
    "    r = random.randint(0,100)\n",
    "    if r <= test_percent:\n",
    "        split = \"test\"\n",
    "    else:\n",
    "        split = \"train\"\n",
    "    \n",
    "    while x_cord + patch_size <= image.size[0]:\n",
    "        while y_cord + patch_size <= image.size[1]:\n",
    "            \n",
    "            # Crop Image\n",
    "            patch = image.crop((x_cord, y_cord, x_cord + patch_size, y_cord + patch_size))\n",
    "            patch = patch.convert('RGB')\n",
    "            patch = patch.resize((resize_to, resize_to))\n",
    "            \n",
    "            # Crop Instance and Class map\n",
    "            inst_patch = inst.crop((x_cord, y_cord, x_cord + patch_size, y_cord + patch_size))\n",
    "            clz_patch = clz.crop((x_cord, y_cord, x_cord + patch_size, y_cord + patch_size))\n",
    "            \n",
    "            # Generate filename\n",
    "            filename = file.split('.')[0] + '__' + str(x_cord) + '_' + str(y_cord) + '.png'\n",
    "            \n",
    "            # Save image, class, instance\n",
    "            patch.save(os.path.join(target_images_path, split, filename))\n",
    "            clz_patch.save(os.path.join(target_classes_path, split, filename))\n",
    "            inst_patch.save(os.path.join(target_instances_path, split, filename))\n",
    "                        \n",
    "            # Taking care of overlap\n",
    "            y_cord = int(y_cord + (1 - overlap) * patch_size)\n",
    "            \n",
    "            # If next window is over the edge, re-fit window and set last flag\n",
    "            if y_cord + patch_size > image.size[1]:\n",
    "                if last_y == False:\n",
    "                    y_cord = image.size[1] - patch_size\n",
    "                    last_y = True\n",
    "        \n",
    "        # Taking care of overlap\n",
    "        x_cord = int(x_cord + (1 - overlap) * patch_size)\n",
    "        # Adjust for last row\n",
    "        if x_cord + patch_size > image.size[0]:\n",
    "            if last_x == False:\n",
    "                x_cord = image.size[0] - patch_size\n",
    "                last_x = True\n",
    "        # Reset y-coordinate back to 0\n",
    "        y_cord = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/as3ek/github/histofusion/done_norm_bright2.txt', 'w') as f:\n",
    "    f.write('Finished Patching!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fastai]",
   "language": "python",
   "name": "conda-env-.conda-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
