{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48337/48337 [01:11<00:00, 677.94it/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# List of prefixes to match\n",
    "prefixes_to_match = ['consep_4_', 'consep_5_', 'consep_6_', 'crag_55_', 'crag_56_', 'crag_58_', 'crag_59_', 'crag_5_', 'crag_60_', 'crag_61_', 'crag_62_', 'crag_63_', 'dpath_52_', 'dpath_53_', 'dpath_54_', 'dpath_55_', 'dpath_56_', 'dpath_57_', 'dpath_58_', 'dpath_59_', 'dpath_5_', 'dpath_60_', 'glas_49_', 'glas_4_', 'glas_50_', 'glas_51_', 'glas_52_', 'glas_53_', 'glas_54_', 'glas_55_', 'glas_56_', 'pannuke_26_', 'pannuke_27_', 'pannuke_28_', 'pannuke_2_', 'pannuke_3_']\n",
    "\n",
    "# Target folder to move the files to\n",
    "target_folder = '/home/as3ek/data/lizard_split_norm_bright3/images/train_sub1/'  # Replace with the actual target folder path\n",
    "\n",
    "# Source folder where your files are located\n",
    "source_folder = '/home/as3ek/data/lizard_split_norm_bright3/images/train/'  # Replace with the actual source folder path\n",
    "\n",
    "# List all files in the source folder\n",
    "files = os.listdir(source_folder)\n",
    "\n",
    "# Loop through the files and move the ones with matching prefixes to the target folder\n",
    "for file in tqdm(files):\n",
    "    for prefix in prefixes_to_match:\n",
    "        if file.startswith(prefix):\n",
    "            source_file = os.path.join(source_folder, file)\n",
    "            target_file = os.path.join(target_folder, file)\n",
    "            shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48337/48337 [00:58<00:00, 823.96it/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# List of prefixes to match\n",
    "prefixes_to_match = ['consep_4_', 'consep_5_', 'consep_6_', 'crag_55_', 'crag_56_', 'crag_58_', 'crag_59_', 'crag_5_', 'crag_60_', 'crag_61_', 'crag_62_', 'crag_63_', 'dpath_52_', 'dpath_53_', 'dpath_54_', 'dpath_55_', 'dpath_56_', 'dpath_57_', 'dpath_58_', 'dpath_59_', 'dpath_5_', 'dpath_60_', 'glas_49_', 'glas_4_', 'glas_50_', 'glas_51_', 'glas_52_', 'glas_53_', 'glas_54_', 'glas_55_', 'glas_56_', 'pannuke_26_', 'pannuke_27_', 'pannuke_28_', 'pannuke_2_', 'pannuke_3_']\n",
    "\n",
    "# Target folder to move the files to\n",
    "target_folder = '/home/as3ek/data/lizard_split_norm_bright3/classes/train_sub1/'  # Replace with the actual target folder path\n",
    "\n",
    "# Source folder where your files are located\n",
    "source_folder = '/home/as3ek/data/lizard_split_norm_bright3/classes/train/'  # Replace with the actual source folder path\n",
    "\n",
    "# List all files in the source folder\n",
    "files = os.listdir(source_folder)\n",
    "\n",
    "# Loop through the files and move the ones with matching prefixes to the target folder\n",
    "for file in tqdm(files):\n",
    "    for prefix in prefixes_to_match:\n",
    "        if file.startswith(prefix):\n",
    "            source_file = os.path.join(source_folder, file)\n",
    "            target_file = os.path.join(target_folder, file)\n",
    "            shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48337/48337 [01:03<00:00, 763.14it/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# List of prefixes to match\n",
    "prefixes_to_match = ['consep_4_', 'consep_5_', 'consep_6_', 'crag_55_', 'crag_56_', 'crag_58_', 'crag_59_', 'crag_5_', 'crag_60_', 'crag_61_', 'crag_62_', 'crag_63_', 'dpath_52_', 'dpath_53_', 'dpath_54_', 'dpath_55_', 'dpath_56_', 'dpath_57_', 'dpath_58_', 'dpath_59_', 'dpath_5_', 'dpath_60_', 'glas_49_', 'glas_4_', 'glas_50_', 'glas_51_', 'glas_52_', 'glas_53_', 'glas_54_', 'glas_55_', 'glas_56_', 'pannuke_26_', 'pannuke_27_', 'pannuke_28_', 'pannuke_2_', 'pannuke_3_']\n",
    "\n",
    "# Target folder to move the files to\n",
    "target_folder = '/home/as3ek/data/lizard_split_norm_bright3/instances/train_sub1/'  # Replace with the actual target folder path\n",
    "\n",
    "# Source folder where your files are located\n",
    "source_folder = '/home/as3ek/data/lizard_split_norm_bright3/instances/train/'  # Replace with the actual source folder path\n",
    "\n",
    "# List all files in the source folder\n",
    "files = os.listdir(source_folder)\n",
    "\n",
    "# Loop through the files and move the ones with matching prefixes to the target folder\n",
    "for file in tqdm(files):\n",
    "    for prefix in prefixes_to_match:\n",
    "        if file.startswith(prefix):\n",
    "            source_file = os.path.join(source_folder, file)\n",
    "            target_file = os.path.join(target_folder, file)\n",
    "            shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os, random\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import math\n",
    "import blobfile as bf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_arr(pil_class, image_size, keep_aspect=True):\n",
    "    pil_class = pil_class.resize(image_size, resample=Image.NEAREST)\n",
    "    arr_class = np.array(pil_class)\n",
    "    return arr_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = torchvision.transforms.Compose([\n",
    "    T.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {}\n",
    "        \n",
    "# Load mask\n",
    "mPATH = \"/home/as3ek/data/lizard_split_norm_bright3/classes/test/\"\n",
    "path = os.listdir(\"/home/as3ek/data/lizard_split_norm_bright3/classes/test/\")[9]\n",
    "path = os.path.join(mPATH, path)\n",
    "\n",
    "with bf.BlobFile(path, \"rb\") as f:\n",
    "    pil_mask = Image.open(f)\n",
    "    pil_mask.load()\n",
    "pil_mask = pil_mask.convert(\"L\")\n",
    "\n",
    "# Resize mask\n",
    "arr_mask = resize_arr(pil_mask, (128,128))[None, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 2],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make into one-hot map\n",
    "label_map = torch.tensor(arr_mask).long()\n",
    "\n",
    "bs, _, h, w = label_map.size()\n",
    "nc = self.num_classes\n",
    "input_label = torch.FloatTensor(bs, nc, h, w).zero_()\n",
    "input_semantics = input_label.scatter_(1, label_map, 1.0)\n",
    "\n",
    "# One-hot condition\n",
    "cond = torch.sum(torch.sum(input_semantics, dim=2), dim=2).bool().int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one-hot label map\n",
    "label_map = torch.tensor(arr_mask).long()\n",
    "bs, _, h, w = label_map.size()\n",
    "nc = 7\n",
    "input_label = torch.FloatTensor(bs, nc, h, w).zero_()\n",
    "input_semantics = input_label.scatter_(1, label_map, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.sum(input_semantics, dim=2), dim=2).bool().int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (torch.rand([input_semantics.shape[0], 1, 1, 1]) > 0.2).float()\n",
    "input_semantics = input_semantics * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'guided_diffusion'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mguided_diffusion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscript_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     model_and_diffusion_defaults,\n\u001b[1;32m      3\u001b[0m     create_model_and_diffusion,\n\u001b[1;32m      4\u001b[0m     args_to_dict,\n\u001b[1;32m      5\u001b[0m     add_dict_to_argparser,\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'guided_diffusion'"
     ]
    }
   ],
   "source": [
    "from guided_diffusion.script_util import (\n",
    "    model_and_diffusion_defaults,\n",
    "    create_model_and_diffusion,\n",
    "    args_to_dict,\n",
    "    add_dict_to_argparser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input_mask(labels, num_classes=7):\n",
    "    label_map = torch.cat([torch.tensor(arr_mask).long().unsqueeze(0), torch.tensor(arr_mask).long().unsqueeze(0)], dim=0)\n",
    "\n",
    "    bs, _, h, w = label_map.size()\n",
    "    nc = num_classes\n",
    "    input_label = torch.FloatTensor(bs, nc, h, w).zero_()\n",
    "    input_semantics = input_label.scatter_(1, label_map, 1.0)\n",
    "\n",
    "    # One-hot condition\n",
    "    cond = torch.sum(torch.sum(input_semantics, dim=2), dim=2).bool().int()\n",
    "\n",
    "    return cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_input_mask(arr_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/as3ek/.conda/envs/hist/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5443,  1.0235, -0.8879],\n",
      "         [ 0.8328, -1.0691,  0.9407],\n",
      "         [ 0.8328, -1.0691,  0.9407],\n",
      "         [ 0.8328, -1.0691,  0.9407],\n",
      "         [ 0.8328, -1.0691,  0.9407]],\n",
      "\n",
      "        [[ 0.8328, -1.0691,  0.9407],\n",
      "         [ 0.8328, -1.0691,  0.9407],\n",
      "         [ 0.5443,  1.0235, -0.8879],\n",
      "         [ 0.8328, -1.0691,  0.9407],\n",
      "         [ 0.8328, -1.0691,  0.9407]],\n",
      "\n",
      "        [[ 0.8328, -1.0691,  0.9407],\n",
      "         [ 0.8328, -1.0691,  0.9407],\n",
      "         [ 0.8328, -1.0691,  0.9407],\n",
      "         [ 0.5443,  1.0235, -0.8879],\n",
      "         [ 0.8328, -1.0691,  0.9407]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the number of categories and the embedding dimension\n",
    "num_categories = 5\n",
    "embedding_dim = 3\n",
    "\n",
    "# Create one-hot tensors for multiple categories\n",
    "categories = torch.tensor([[1, 0, 0, 0, 0],  # Category 1\n",
    "                           [0, 0, 1, 0, 0],  # Category 3\n",
    "                           [0, 0, 0, 1, 0]])  # Category 4\n",
    "\n",
    "# Define the embedding layer\n",
    "embedding_layer = nn.Embedding(num_categories, embedding_dim)\n",
    "\n",
    "# Convert the one-hot tensors into embeddings\n",
    "embeddings = embedding_layer(categories)\n",
    "\n",
    "# The 'embeddings' variable now contains the embeddings for multiple one-hot vectors\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hist",
   "language": "python",
   "name": "hist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
